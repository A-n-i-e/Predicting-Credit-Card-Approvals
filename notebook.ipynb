{"cells":[{"cell_type":"code","execution_count":3,"id":"6e86b1e8-a3fa-4b09-982f-795f218bd1a6","metadata":{"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"},"executionCancelledAt":null,"executionTime":35,"lastExecutedAt":1716295516305,"lastExecutedByKernel":"6e0f2cf7-29b7-43c1-8f4a-805e2c3d45f4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()\n","outputsMetadata":{"0":{"height":193,"type":"dataFrame"}},"visualizeDataframe":false},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b</td>\n","      <td>30.83</td>\n","      <td>0.000</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>1.25</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>1</td>\n","      <td>g</td>\n","      <td>0</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>a</td>\n","      <td>58.67</td>\n","      <td>4.460</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>3.04</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>6</td>\n","      <td>g</td>\n","      <td>560</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>a</td>\n","      <td>24.50</td>\n","      <td>0.500</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>q</td>\n","      <td>h</td>\n","      <td>1.50</td>\n","      <td>t</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>g</td>\n","      <td>824</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>b</td>\n","      <td>27.83</td>\n","      <td>1.540</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>3.75</td>\n","      <td>t</td>\n","      <td>t</td>\n","      <td>5</td>\n","      <td>g</td>\n","      <td>3</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>b</td>\n","      <td>20.17</td>\n","      <td>5.625</td>\n","      <td>u</td>\n","      <td>g</td>\n","      <td>w</td>\n","      <td>v</td>\n","      <td>1.71</td>\n","      <td>t</td>\n","      <td>f</td>\n","      <td>0</td>\n","      <td>s</td>\n","      <td>0</td>\n","      <td>+</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n","0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n","1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n","2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n","3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n","4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","\n","# Load the dataset\n","cc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \n","cc_apps.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["Preprocessing Data:\n","\n","- Replacing missing values with NaN\n","- Imputing missing values in dataset"]},{"cell_type":"code","execution_count":4,"id":"b9610fb6-ac18-49b2-b0d5-71cbda31939b","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1716295516357,"lastExecutedByKernel":"6e0f2cf7-29b7-43c1-8f4a-805e2c3d45f4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#print(cc_apps.isna().sum().sort_values()) \ncc_apps = cc_apps.replace(\"?\",np.NaN)\ncc_apps_copy = cc_apps.copy()\n\n                          \nfor column in cc_apps_copy.columns:\n    if cc_apps_copy[column].dtypes ==  \"object\":\n          cc_apps_copy[column] = cc_apps_copy[column].fillna(cc_apps_copy[column].value_counts().index[0])  \n    else:\n        cc_apps_copy[column] = cc_apps_copy[column].fillna(cc_apps_copy[column].mean())\ncc_apps_encod =pd.get_dummies(cc_apps_copy, drop_first = \"True\")   \n\n\n","outputsMetadata":{"0":{"height":210,"type":"dataFrame"}}},"outputs":[],"source":["\n","cc_apps = cc_apps.replace(\"?\",np.NaN)\n","cc_apps_copy = cc_apps.copy()\n","\n","                          \n","for column in cc_apps_copy.columns:\n","    if cc_apps_copy[column].dtypes ==  \"object\":\n","          cc_apps_copy[column] = cc_apps_copy[column].fillna(cc_apps_copy[column].value_counts().index[0])  \n","    else:\n","        cc_apps_copy[column] = cc_apps_copy[column].fillna(cc_apps_copy[column].mean())\n","cc_apps_encod =pd.get_dummies(cc_apps_copy, drop_first = \"True\")   \n","\n","\n"]},{"cell_type":"markdown","id":"9fe9f3ec","metadata":{},"source":["Preparing data for modelling:\n","\n","- Defining feature and target variables\n","- Splitting data\n","- Scaling data"]},{"cell_type":"code","execution_count":5,"id":"8199aef9-5887-4359-8234-fca94830ef05","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1716295516405,"lastExecutedByKernel":"6e0f2cf7-29b7-43c1-8f4a-805e2c3d45f4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"X = cc_apps_encod.iloc[:, :-1].values\nprint(X[:5])\ny = cc_apps_encod.iloc[:, [-1]].values\nprint(y[:10])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","outputsMetadata":{"0":{"height":332,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 1.25 1 ... True False False]\n"," [4.46 3.04 6 ... True False False]\n"," [0.5 1.5 0 ... False False False]\n"," [1.54 3.75 5 ... True False False]\n"," [5.625 1.71 0 ... False False True]]\n"]}],"source":["X = cc_apps_encod.iloc[:, :-1].values\n","print(X[:5])\n","y = cc_apps_encod.iloc[:, [-1]].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"markdown","id":"b0b0fe95-c1e9-46df-bf50-a2d617d822b8","metadata":{},"source":["- Defining Model\n","- Training and testing model without Hyperparameter Tuning"]},{"cell_type":"code","execution_count":41,"id":"2a05790a-72cf-432a-a342-57cb4c083590","metadata":{"executionCancelledAt":null,"executionTime":460,"lastExecutedAt":1716295516865,"lastExecutedByKernel":"6e0f2cf7-29b7-43c1-8f4a-805e2c3d45f4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nprediction = logreg.predict(X_test)\n\n\nprint(accuracy_score(y_test, prediction))\nprint(confusion_matrix(y_test, prediction))","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7971014492753623\n","[[46 16]\n"," [12 64]]\n"]}],"source":["logreg = LogisticRegression()\n","logreg.fit(X_train, y_train)\n","prediction = logreg.predict(X_test)\n","\n","\n","print(accuracy_score(y_test, prediction))\n","print(confusion_matrix(y_test, prediction))"]},{"cell_type":"markdown","id":"c6928c42-65e2-468e-b9c4-8ad7e7427eb4","metadata":{},"source":["Using GridSearchCV to improve the parameters and get a better model accuracy"]},{"cell_type":"code","execution_count":42,"id":"a8418f33-6eb1-442b-b6b0-a56142c3e99f","metadata":{"executionCancelledAt":null,"executionTime":5701,"lastExecutedAt":1716295522566,"lastExecutedByKernel":"6e0f2cf7-29b7-43c1-8f4a-805e2c3d45f4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"param_grid = {\n    'penalty': ['l1', 'l2'],\n    'C': [0.001, 0.01, 0.1, 1, 10, 100]\n\n}\ngrid_cv = GridSearchCV(logreg, param_grid, cv = 5)\ngrid_cv.fit(X_train, y_train)\npredictions_2 = grid_cv.predict(X_test)\n\nprint(confusion_matrix(y_test, predictions_2))\n\nbest_score = grid_cv.best_score_\nbest_parameter = grid_cv.best_params_\n\nprint(f\"Best Score: {best_score} and Parameters used: {best_parameter}\")","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["[[45 17]\n"," [10 66]]\n","Best Score: 0.8478296478296479 and Parameters used: {'C': 0.01, 'penalty': 'l2'}\n"]}],"source":["param_grid = {\n","    'penalty': ['l1', 'l2'],\n","    'C': [0.001, 0.01, 0.1, 1, 10, 100]\n","\n","}\n","grid_cv = GridSearchCV(logreg, param_grid, cv = 5)\n","grid_cv.fit(X_train, y_train)\n","predictions_2 = grid_cv.predict(X_test)\n","\n","print(confusion_matrix(y_test, predictions_2))\n","\n","best_score = grid_cv.best_score_\n","best_parameter = grid_cv.best_params_\n","\n","print(f\"Best Score: {best_score} and Parameters used: {best_parameter}\")"]},{"cell_type":"markdown","id":"eaad129d-0f31-4001-bb4c-7756db52a29a","metadata":{},"source":["Accuracy increased from 79.7% to 84.7% after Hyper parameter tuning was done on the logistic regression model"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":5}
